# 系统架构笔记

## 一、项目技术栈

本项目基于以下技术框架构建：

- **MCP**：基于客户端-服务器架构  
  - 主机：LLM 应用程序（服务端）  
  - 客户端：运行于主机应用中的交互模块，与服务端保持 1:1 连接  
  - 协议：基于 `JSON-RPC 2.0` 的客户端-服务器通信协议  
  - 职责划分：
    - 服务器提供上下文、工具、提示
    - 客户端主要负责接收输出和用户输入交互

- **LangChain + LangGraph**：
  - LangChain：负责构建 RAG（Retrieval Augmented Generation）相关逻辑
  - LangGraph：用于智能体 Agent 的定义和图结构的构建

- **Chainlit**：
  - 快速搭建基于 Chat 的网页应用
  - 提供完整的 UI 组件和聊天逻辑封装

---

## 二、项目结构设计

项目采用 `LangGraph Server CLI` 脚手架构建，整体划分为以下模块：

### 1. `app` 模块
- 负责用户交互界面的开发
- 集成了 Chainlit UI，快速构建 Chat 界面

### 2. `server` 模块
- MCP 服务端定义模块
- 注册工具、上下文和服务逻辑

### 3. `clients` 模块
- MCP 客户端逻辑
- 实现模型调用和用户指令的响应处理

### 4. `rag` 模块
- 专注于 RAG 检索流程
- 包括文件上传、向量化、检索、答案生成等功能

### 5. `agent` 模块
- 开发各类 Agent 智能体
- 已完成：RAG Agent、问答 Agent

### 6. `workflows` 模块
- 构建 LangGraph 的工作流定义
- 管理状态、记忆、Agent 路由逻辑

---

## 三、项目亮点

1. **完整的 RAG 流程集成**：支持文件上传、分段、检索、问答的全链路功能
2. **多 Agent 架构设计**：模块化的智能体支持灵活组合与扩展
3. **技术创新突破**：MCP 与 LangChain 工具的适配实现

---

## 四、技术难点与挑战

### 1. MCP 与 LangChain 工具适配困难

**核心问题：**
- **上下文不共享**：MCP 的服务端工具与 LangChain 的客户端图不共享运行时上下文，无法直接访问配置参数
- **参数乱码传输**：尤其在传输字典类型参数时出现乱码现象，尽管服务端日志显示乱码，整体程序仍运行正常，存在安全隐患

---

## 五、解决方案详解

### 运行时参数适配问题

**官方适配器限制：**
- LangChain 的工具必须依赖模型生成完整的参数输入，无法传递运行时配置
- 原计划通过 `langchain.tools.Tool` 封装 MCP 工具，但实现复杂、意义不大

**改进方案：**
- 改写 `mcp-langchain` 官方适配器源码
- 在工具调用函数中新增运行时配置参数，并自动注入配置内容

**实现思路：**

```
1. 调用工具函数支持接收运行时配置
2. 通过工具输入架构提取必需的参数名
3. 使用深拷贝拷贝运行时配置
4. 遍历输入参数字段：
   - 若运行时配置包含对应字段 → 替换默认值
   - 否则保持模型生成的默认值不变
```

# 未来规划
1. RAG优化
2. 模型调用优化
3. 工具智能体调用优化
4. 丰富工具内容
5. Chainlit优化

